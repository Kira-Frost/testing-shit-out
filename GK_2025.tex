\documentclass[12pt]{amsart}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{xcolor}
%%%%%
\newcommand{\D}{\mathcal{D}}
\newcommand{\x}{x}
\newcommand{\norm}[1]{|#1|}
\newcommand{\dnorm}[2]{||#1||_{#2}}
\newcommand{\hnorm}[2]{\dnorm{#1}{H^{#2}}}
\newcommand{\comment}[1]{}
%%%%%


\newtheorem{theorem}{Theorem}[section]
\newtheorem{problem}[theorem]{Problem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corol}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}

\theoremstyle{definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{remarks}[theorem]{Remarks}
\newtheorem{example}[theorem]{Example}


\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Cl}{\R_{0,n}}
\newcommand{\del}{\delta}
\newcommand{\inci}{\subseteq}
\newcommand{\ba}{\overline}
\newcommand{\Om}{\Omega}
\newcommand{\un}{\underline}



\begin{document}

\title[Dirac operators with distributional coefficients]{Very weak solutions of Dirac operators with distributional coefficients }


\author[N. Gomes]{N. Gomes}
\address{(NG) CIDMA - Center for Research and Development in Mathematics and Applications, \newline Universidade de Cabo Verde \newline Campus 
  \newline Praia, Cabo Verde}
\email{}

\author[K. Morozov]{K. Morozov}
\address{(KM) CIDMA - Center for Research and Development in Mathematics and Applications, \newline Department of Mathematics, University of Aveiro \newline Campus Universit\'ario de Santiago
  \newline 3810-193 Aveiro, Portugal}
\email{}

%
%
\subjclass[2010]{Primary: 30G35; Secondary: }
%
%\date{}
\keywords{Dirac operator, very weak solution}
%%%%%%%%%%%%%





\begin{abstract}
In this paper we will discuss the possibility to study very weak solutions of Dirac operators with distributional coefficients. To this end we need to adapt classic methods like CK-extension from hypercomplex analysis to this case and combine it with techniques developed by M. Ruzhansky and his collaborators. 
\end{abstract}

\maketitle



\section{Introduction}

One of the interesting problems in the theory of partial differential equations is the study of differential equations with distributional coefficients. Unfortunately, there exists a major obstacle. Since the point-wise multiplication of distributions is ill-defined even questions as simple as the existence of a solution becomes a major challenge. 

During the last decade M. Ruzhansky and his collaborators introduces a new concept of a solution, so-called very weak solutions, whereby the solution is given in terms of a net or family of regularized solutions. 

As far as we know up to now this concept was not adapted to the case of differential equations in the context of hypercomplex analysis.

In this paper we will consider the following Cauchy problem:
\begin{equation}
  \begin{cases}
\partial_{x_0} u(x_0+\un{x}) + a(x_0)D u(x_0+\un{x}) = 0, & \text{with } x \in (0, T]\times\Omega, \\
u(0,\un{x}) = u_0(\un{x}),\;\; \un{x}\in \Omega,
\end{cases}
\label{CP}  
\end{equation}
where $D := \sum_{k=1}^n e_k \partial_{x_k}$ is the Dirac operator, and $e_k$ are elements of a Clifford algebra satisfying $e_k e_j + e_j e_k = -2\delta_{kj}$.
%%%%%%%%%%%%% Theorem 1 and Theorem 2 %%%%%%%%%%%%%%%%

\begin{theorem}
\label{th1.1}
Let \(x_0 > 0\). Let \(a \in \mathrm{Lip}([0, T])\) with \(a(x_0) \geq a_0 > 0\). Given \(s \in \mathbb{R}\), if the initial Cauchy data \(u_0\) are in \(H^{s}(\Omega)\), then there exists the unique solution of the homogeneous Cauchy problem~(\ref{CP}) (when \(f \equiv 0\)) in the space \(C([0, T], H^{s})\), satisfying the following inequality for all values of \(x_0 \in [0, T]\):
    \begin{equation*}
    \label{eq:1.5}
          \| u(t, \cdot) \|_{H^s(\Omega)}^2  \leq C \| u_0 \|_{H^s(\Omega)}^2 .
    \end{equation*}
\end{theorem}

\begin{theorem}
\label{th1.2}
Let \(x_0 > 0\). Then we have:
Let \(a \in \mathrm{Lip}([0, T])\) with \(a(x_0) \geq a_0 > 0\). Given \(s \in \mathbb{R}\), if \(f \in C([0, T], H^{s}(\Omega))\) and the initial Cauchy data \(u_0\) are in \(H^s\), then there exists a unique solution of~(\ref{CP}) in the space \(C([0, T], H^s(\Omega))\), satisfying the following inequality for all values of \(x_0 \in [0, T]\):
    \begin{equation}
    \label{eq:1.6}
    \| u(t, \cdot) \|_{H^s(\Omega)}^2  \leq C\left(\| u_0 \|_{H^s(\Omega)}^2+\| f\|_{C([0, T], H^{s}(\Omega))}^2\right).
   \end{equation}
\end{theorem}

\section{Preliminaries}

Let $\{e_1,e_2,\ldots,e_n\}$ be an orthonormal basis of $\R^n$. We consider the $2^n$-dimensional real Clifford algebra $\R_{0,n}$ generated by $e_1,e_2,\ldots,e_n$ subject to the condition 
$$
x^2=-|x|^2 \mbox{ for all } x\in\mathbb{R}^n.
$$
where $|x|^2=x_1^2+\cdots +x_n^2$. 

This means that the basis elements satisfy the multiplication rules $e_ie_j=-e_je_i$ for $i\neq j$, . The elements $e_A : A\subseteq \N_n:=\{1,2,\ldots, n+1\}$ define a basis of $\R_{0,n}$, where $e_A=e_{h_1}\cdots e_{h_k}$ if $A=\{h_1, \ldots,h_k\}$ $(1\leq h_1<\cdots<h_k\leq n)$ and $e_\emptyset=e_0=1$. Therefore, any element $a\in\R_{0,n}$ may thus be written as $a=\sum_{A\inci\N_n}a_Ae_A$ where $a_A\in\R$ or still as $a=\sum_{k=0}^n[a]_k$, where {$[a]_k=\sum_{|A|=k}a_A e_A$} is a so-called $k$-vector part $(k\in\N_n^0:=\N_n\cup\{0\})$. Denoting the space of $k$-vectors by $\R_{0,n}^{(k)}$ we have $\R_{0,n}=\oplus_{k=0}^n\R_{0,n}^{(k)}$. This also introduces a grading into our algebra.

Hereby, the spaces $\R$ and $\R^n$ will be identified with 
 $\R_{0,n}^{(0)}$ and $\R_{0,n}^{(1)}$ respectively. This means that each element $x=(x_0, x_1,\ldots, x_n)\in\R^{n+1}$ can be written as
	\[x=x_0+ \sum_{i=1}^nx_ie_i\in\R_{1,n}^{(0)}\oplus\R_{1,n}^{(1)}
\]
and are often called {\it paravectors}. 


We will use the {\it conjugation}, an anti-automorphism which is defined by $\bar{a}=\sum_{A\inci\N_n}a_A\bar{e}_A$, where 
	\[\bar{e}_A:=(-1)^ke_{h_k}\cdots e_{h_1}=(-1)^{\frac{k(k+1)}{2}}e_A, \hspace{.5cm}\mbox{ if  } \hspace{.3cm} e_A=e_{h_1}\cdots e_{h_k}.
\]

For each $x\in \R_{0,n}^{(0)}\oplus\R_{0,n}^{(1)}$ we have 
\begin{equation}\label{Par Norm}
x\bar{x}=\bar{x}x=x_0^2+x_\epsilon^2 + x_1^2+\cdots+x_n^2=|x|^2.
\end{equation}
The extension of (\ref{Par Norm}) to a norm of $a\in\R_{0,n}$ is straightforward and leads to 
	\[|a|^2=[a\bar{a}]_0=[\bar{a}a]_0=\sum_A a_A^2.
\]

The following properties of the norm and conjugation in Clifford algebras are well-known and can be found in many sources, see for instance \cite{DSS}. 
\begin{proposition}
Let $a,b\in\Cl$, then
\begin{itemize}
  \item[(i)] $\ba{ab}=\bar{b}\; \bar{a}$,
	\item[(ii)] $|\bar{a}|=|-a|=|a|$ 
	\item[(iii)] $\left[a\bar{b}\right]_0=\big[\bar{a}b\big]_0=\langle a, b\rangle_{\R^{2^n}}$, where $\langle \cdot, \cdot\rangle_{\R^m}$ denote the standard scalar product in $\R^{m}$,
	\item[(iv)] $|ab|\leq 2^{n/2}|a||b|$,
	\item[(v)] if $b$ is such that $b\bar{b}=|b|^2$, $b\neq 0$, then $b$ is invertible and $|ab|=|ba|=|a||b|$.
\end{itemize}
\end{proposition}

Suppose $\Omega\subset\mathbb{R}^{n}$ is a bounded domain, with sufficiently smooth boundary $\Gamma$. We consider a domain $\Omega_T=[0,T]\times\Omega$. We will be interested in functions $f:\Omega_T \rightarrow\R_{0,n}$, which might be written as $f(x)=\sum_{A}f_A(x)e_A$ with $f_A$ being $\R$-valued. Property, such continuity, differentiability, integrability, and so on, can be ascribed coordinate-wise or directly. A left (unitary) module over $\R_{0,n}$ is a vector space $V$ together with an algebra morphism $L:\R_{0,n}\mapsto \mathrm{End}(V)$, or to say it more explicitly, there exists a linear transformation (also called left multiplication) $L(a)$ of $V$ such that
$$
L(ab+c)=L(a)L(b)+L(c)
$$ 
for all $a\in\R_{0,n}$, and $L(1)$ is the identity operator. In the same way we have a right (unitary) module if there is a so-called right multiplication $R(a)\in  \mathrm{End}(V)$ such that
$$
R(ab+c)=R(b)R(a)+R(c).
$$
Given either a left or a right multiplication we can always construct a right or a left multiplication by using any anti-automorphism of the algebra, for instance
$$
R(a)=L(\ba{a}).
$$
A bi-module is a module which is both a left- and a right-module, or with other words, a module where left and right multiplication commute, i.e. 
$$
L(a)R(b)=R(b)L(a), \mbox{ for all }a,b\in \R_{0,n}.
$$
If $V$ is a vector space of $\R_{0,n}$-valued function we consider the left (right) multiplication defined by pointwise multiplication
$$
(L(a)f)(x)=a(f(x)) \mbox{ and } (R(a)f)(x)=a(f(x)).
$$
Also a mapping $K$ between two right modules $V$ and $W$ is called a $\R_{0,n}$-linear mapping if
$$
K(fa+g)=K(f)a+K(g).
$$
This considerations give rise to the following right modules of $\R_{0,n}$-valued functions defined over any suitable subset $E$ inside the null-cone of $\R^{1,n}$:
\begin{itemize}
	\item $C^k(E,\Cl), k\in\mathcal{N}\cup\{0\}$-- the right module of all $\Cl$-valued functions, $k$-times continuously differentiable in $E$. It becomes a right Banach module with the norm
	$$
	\|f\|_{C^k}=\sup_{x\in E}\sum_{|\alpha|\leq k}|D^\alpha_w f(x)|
	$$
where $\alpha$ denotes a multi-index and $D^\alpha$ the corresponding partial derivative. In particular, we also have $C^\infty(E,\Cl):=\bigcap_{k=0}^\infty C^k(E,\Cl)$. Let us remark that the above norm is equivalent to the norm coming from the inductive limit.

\item By using the corresponding H\"older-semi-norm we can introduce $C^{0,\mu}(E, \Cl)$, $\mu\in(0,1]$, as the right Banach module of all $\mu$-H\"older continuous and $\Cl$-valued functions in $E$. 
\item $L_p(E,\Cl)$, $1\leq p<\infty$, denotes the right module of all equivalence classes of Lebesgue measurable functions $f:E\mapsto\Cl$ for which $|f|^p$ is integrable over $E$.  With the norm
  \[||f||_{L_p(E,\Cl)}:=\left(\int_E |f(\xi)|^p\;d\xi\right)^{1/p}<\infty,
\]
$L_p(E,\Cl)$ becomes a right Banach module.
\item $C^\infty_0(E,\Cl)$-- the space of all infinitely differentiable functions with compact support in $E$. An important property of the space $C^\infty_0(E,\Cl)$ is its density in the spaces $C^0(E,\Cl)$ and $L_p(E,\Cl)$.
\end{itemize}

Furthermore, the above proposition allows us to introduce the following sesquilinear form (also called symmetric inner product in the literature) for two functions $f,g:\Omega\rightarrow$ $\Cl$
$$
(f,g):=\ba{f}g.
$$
In particular, this sesquilinear form is a real-bilinear mapping and a Clifford-linear mapping in the second argument. 
Furthermore, this sesquilinear form gives rise to a real-valued positive definite inner product 
$$
\langle f,g\rangle=[(f,g)]_0
$$
with $\langle f,f\rangle=|f|^2$. This allows us to consider the space $L_2(E, \Cl)$ as a Hilbert module which is complete under the norm coming from the real-valued inner product
\begin{equation}\label{Pro Int}
\left\langle f,g\right\rangle_{2,R}=\int_E [\ba{f(\xi)} g(\xi)\,]_0 d\xi. 
\end{equation}
Since the real-valued inner product and its norm are coming from the restriction of a $\Cl$-valued sesquilinear form
$$
\left\langle f,g\right\rangle_{2}=\int_E \ba{f(\xi)} g(\xi)\, d\xi
$$
many proofs which only involve identities can be shown for the sesquilinear form and then reduced to the real-valued inner product on both sides. Because of this fact one usually considers the Hilbert module equipped with the $\Cl$-valued inner product $\langle\cdot,,\cdot\rangle_{2}$. In particular, a generalization of Riesz' representation theorem is valid in the sense that a linear functional $\phi$ is continuous if and only if it can be represented by an element $f_\phi\in V$ such that
$$
\phi(g)=\langle f_\phi,g\rangle_{2}.
$$
Additionally, there are some important inequalities involving the sesquilinear form and the norm coming from the real-valued inner product:
\begin{itemize}
\item Cauchy-Schwarz inequality: $|\langle f,g\rangle_2|\leq 2^{n/2}\|f\|_{L_p(E,\Cl)} \|g\|_{L_q(E,\Cl)}$ with $\frac{1}{p}+\frac{1}{q}=1$
\item $\|a f\|_{L_2(E,\Cl)}\leq 2^{n/2}|a|\|f\|_{L_2(E,\Cl)}$ for all $a\in\Cl$, but $\|a f\|_{L_2(E,\Cl)}=|a|\|f\|_{L_2(E,\Cl)}$ whenever $a$ is a paravector or belongs to the paravector group.
\item $\|f\|_{L_2(E,\Cl)}\leq |\langle f,f \rangle_2|\leq 2^{n/2}\|f\|_{L_2(E,\Cl)}$
\item $\|f\|_{L_2(E,\Cl)}\leq \sup_{\|g\|_{L_2(E,\Cl)} \leq 1}|\langle f,g \rangle_2|\leq 2^{n/2}\|f\|_{L_2(E,\Cl)}$
\end{itemize}
The same statements are also true for any other Clifford Hilbert module coming from a tensor product between the elements of the Clifford basis and elements of a real or complex Hilbert space~\cite{Held}. {\color{red} ADD REFFERENCE ``Held"}.


In the same way we can introduce $\mathcal{S}$ as the corresponding Schwartz space of rapidly decaying functions. Its dual space $\mathcal{S}^\prime$ is given by the continuous linear functionals is the space of tempered distributions.  Again, this can be either defined component-wise or via the sesquilinear form 
$\langle f,g \rangle_{2}$ but the space $\mathcal{S}^\prime$ is again considered as a right module. Let us remark that strictly speaking if we consider $\mathcal{S}$ as a Fr\'echet right module its algebraic dual $\mathcal{S}^\prime$ is the space of all left-$\Cl$-linear functionals over $\mathcal{S}$, but it can be identified with elements of a right-linear module by means of the standard anti-automorphism in the above mentioned way.
 
This allows us to introduce the {\it Sobolev} space $W_p^k(E,\Cl), k\in \mathbb{N}\cup\{0\},1\leq p<\infty$, as the right module of all functionals $f\in \mathcal{S}^\prime$ whose derivatives\footnote{$D^\alpha_w f=\frac{\partial^{|\alpha |}f}{\partial x_0^{\alpha_0}\cdots\partial x_n^{\alpha_n}}$ where $\alpha=(\alpha_0,\ldots,\alpha_n)\in\left(\N\cup\{0\}\right)^{n+1}$ is a multi-index and $|\alpha |=\alpha_0+\cdots+\alpha_n$.}	 $D^\alpha_w f$ for $|\alpha | \leq k$ belong to $L_p(E,\Cl)$, with norm
  $$
  \|f\|_{W_p(E,\Cl)}:=\left(\sum_{\|\alpha\| \leq k}\| D^\alpha_w f \|_{L_p(E,\Cl)}^p\right)^{1/p}.
  $$ 
 Alternatively, we also can consider the Sobolev space  $H_p^S(E,\Cl), s\in \mathbb{R},1\leq p<\infty$, as the right module of all functionals $f\in \mathcal{S}^\prime$ whose extension to $\mathbb{R}^{n+1}$ satisfies
 $$
\hat{f} ( \cdot ) < \cdot >^s \in L_p(E,\Cl)
 $$ 
where $\hat f$ denotes the Fourier transform and $<\xi>=(1+|\xi |^2)^{1/2}$ denotes the Japanese bracket. We remark that when $E$ has the extension property we have $W_p^k(E,\Cl)=H_p^k(E,\Cl)$.
% 
 
For more details we refer to the classic book~\cite{BDS}.

%%%%%%%% Dirac operator in our setting

On the set $C^1(\Om,\Cl)$ we define respectively the classic left and the right Dirac operator by: 
\begin{equation}\label{Op Dif}
D[f]:=\sum_{i=1}^n e_i\frac{\partial f}{\partial x_i}, \hspace{.5cm} [f]D:=\sum_{i=1}^n\frac{\partial f}{\partial x_i}e_i.
\end{equation}
For simplicity of notation we continue to write $\partial_{i}$ instead of $\displaystyle\frac{\partial}{\partial x_i}$. Functions belonging to the kernel of this operator are called left- or right-monogenic functions. In case of left-monogenic functions one simply speaks also of monogenic functions. 

Let $\Delta_{n}$ be the $n$-dimensional Laplace operator. It is easy to prove that the equalities
\begin{equation}\label{Fac Lap}
D^2=-\Delta_{n},
\end{equation}
hold.

In this paper we will consider the non-constant Dirac operator with possibly distributional coefficients of the type
$$
\mathcal{D}f=\frac{\partial}{\partial x_0}+a(x_0)Df :=\frac{\partial}{\partial x_0}+a(x_0)\sum_{i=1}^n e_i\frac{\partial f}{\partial x_i}.
$$

\section{CK-extension in the case of Dirac operators with non-constant coefficients}

The classic CK-extension method allows one to construct monogenic functions over domains in $\R^{n+1}$ from analytic functions over $\R^n$. 

\begin{theorem}
    The CK-Extension
    \[
        CKu_0(x_0, x) = \sum_{k = 0}^\infty \frac{(-1)^k}{k!}[A(x_0)-A(0)]^k\underline{\D}^ku_0(x)
    \]
    solves the following Cauchy problem
    \[
    \begin{cases}
    \partial_{x_0} u(x_0,x) + a(x_0)\underline{\D} u(x_0,x) = 0, & \text{with } x_0 \in (0, T], \\
    u(0,x) = u_0(x),\;\; x\in \Omega,
    \end{cases} 
    \]
    
\end{theorem}
\begin{proof}
It is reasonable to expect that the appropriate CK-Extension for the Cauchy problem (\ref{CP}) will be of the form
\[
CKu_0(x_0, x)=\sum_{k = 0}^\infty \frac{(-1)^k}{k!}\phi(x_0)^k\underline{\D}^ku_0(x),
\]
for some function $\phi$.

If $CK(u)$ is a solution to the differential equation

\[
(\partial_0 + a(x_0)\underline{\D})CKu_0 =0,
\]
then
\begin{align*}
    0 
    &= (\partial_0 + a(x_0)\underline{\D})(\sum_{k = 0}^\infty \frac{(-1)^k}{k!}\phi(x_0)^k\underline{\D}^ku_0(x)) \\
    & = \partial_0[u_0(x) + \sum_{k = 1}^\infty \frac{(-1)^k}{k!}\phi(x_0)^k\underline{\D}^ku_0(x)]\\
    &+a(x_0)\sum_{k = 0}^\infty \frac{(-1)^k}{k!}\phi(x_0)^k\underline{\D}^{k+1}u_0(x) \\
    & = \sum_{k = 1}^\infty \frac{(-1)^k}{(k-1)!}\phi(x_0)^{k-1}\phi'(x_0)\underline{\D}^ku_0(x) \\
    &+\sum_{k = 0}^\infty \frac{(-1)^k}{k!}a(x_0)\phi(x_0)^k\underline{\D}^{k+1}u_0(x) \\
    &= \sum_{k = 0}^\infty \frac{(-1)^{k+1}}{k!}\phi(x_0)^k\phi'(x_0)\underline{\D}^{k+1}u_0(x) \\
    &+\sum_{k = 0}^\infty \frac{(-1)^k}{k!}a(x_0)\phi(x_0)^k\underline{\D}^{k+1}u_0(x) \\
    &= \sum_{k = 0}^\infty [-\phi'(x_0) + a(x_0)]\frac{(-1)^k}{k!}\phi(x_0)^k\underline{\D}^{k+1}u_0(x).
\end{align*}
Since this equality has to hold for every $u_0$ and $\phi$ is non null then,
\[  
-\phi'(x) + a(x) = 0. 
\]
This is an ODE with a classical solution
\[
\phi(x) = \int a(x) dx + C, \qquad C\in \mathbb{R}
\]
For shorthand, let's define $A(x) = \int a(x) dx$.
Given the boundry condition of the Cauchy problem (\ref{CP}),
\begin{align*}
    u_0(x) 
    &= CKu_0(0, x)\\
    &=\sum_{k = 0}^\infty \frac{(-1)^k}{k!}\phi(0)^k\underline{\D}^ku_0(x)\\
    &=\sum_{k = 0}^\infty \frac{(-1)^k}{k!}[A(0)-C]^k\underline{\D}^ku_0(x).
\end{align*}
Since this condition has to hold for every suitable $u_0$,
\[
C = A(0).
\]
As such, when $a$ is integrable,
\[
CKu_0(x_0, x) = \sum_{k = 0}^\infty \frac{(-1)^k}{k!}[A(x_0)-A(0)]^k\underline{\D}^ku_0(x)
\]
is an explicit solution to the Cauchy problem (\ref{CP}). Aditionally, due to the properties of the CK-Extension, when $a$ is infinitely diferentiable the solution is also unique. 
\end{proof}
For infintely differentiable $u_0$, there is a simple norm estimate for the CK-Extension obtained above.

Given that
\[
\dnorm{(x_0\D)u_0}{H^p} \leq \norm{x_0}\dnorm{u_0}{H^{\infty}}. 
\]
It is also true that
\[
\dnorm{(x_0\D)^ku_0}{H^p} \leq \norm{x_0}\dnorm{(x_0\D)^{k-1}u_0}{H^{\infty}}. 
\]
Repeating this step $k$ times:
\[
\dnorm{(x_0\D)^ku_0}{H^p} \leq \norm{x_0}^k\dnorm{u_0}{H^{\infty}}. 
\]
Adapting to our case we have, with $\sup (\norm{A(x_0)-A(0)}) = a_1$,

\[
\hnorm{((A(x_0)-A(0))\D )^k u_0}{p}\leq a_1^k \hnorm{u_0}{\infty}
\]
As such, a possible energy estimate for the CK-Extension is 
\begin{align*}
\hnorm{CKu_0}{p}    &= \hnorm{\sum_{k = 0}^\infty \frac{(-1)^k}{k!}[A(x_0)-A(0)]^k\underline{\D}^ku_0(x)}{p}\\
        &\leq \sum_{k = 0}^\infty \frac{1}{k!}\hnorm{[A(x_0)-A(0)]^k\underline{\D}^ku_0(x)}{p} \\
        &\leq \sum_{k = 0}^\infty \frac{a_1^k}{k!}\hnorm{u_0(x)}{\infty}\\
        &= e^{a_1}\hnorm{u_0(x)}{\infty}.
\end{align*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Energy estimates for Dirac operators with non-constant coefficients}

Let us now take a closer look into energy estimates using a different approach. Considering the case $\Omega=\R^n$ and applying the Fourier transform in the variable $\un{x}$ to~(\ref{CP}) we get
\begin{equation}
\begin{cases}
\partial_{x_0}\hat{u}(x_0,\xi) = i\xi a(x_0)\hat{u}(x_0,\xi), \qquad \xi\in\R^n\\
\hat{u}(0,\xi) = \hat{u}_0(\xi).
\end{cases}
\label{eq3.4-td}
\end{equation}
where $\hat{u}$ denotes the Fourier transform in $\R^n$. Let us furthermore consider $a \in \text{Lip}([0, T]), \, a(x_0) \geq a_0 > 0$. Additionally, we will denote $\hat{u}(x_0,\cdot)=\hat{u}(x_0)$.

Here we define the energy as
\[
E(x_0) := \mathrm{Re}\left(\langle a(x_0)\hat{u}(x_0), \hat{u}(x_0) \rangle\right),
\]
and we need to estimate its variations in the variable $x_0$. Using the fact that $a \in \text{Lip}([0, T])$ and $a(x_0) \geq a_0 > 0$ we have immediately
\begin{equation}
\min_{x_0 \in [0,T]} \{a(x_0)\}\|\hat{u}\|^2\leq E(x_0) \leq \max_{t \in [0,T]} \{a(x_0)\} \|\hat{u}\|^2 .
\label{eq3.5-td}
\end{equation}

In particular, in this case the condition on $a$ ensures the existence of two strictly positive constants $c_0 $ and $ c_1 $ such that $ c_0 = \min_{t \in [0,T]} a(x_0) $ and $ c_1 = \max_{t \in [0,T]} a(x_0) $.

Therefore, inequality~(\ref{eq3.5-td}) can be written as
\begin{equation}
c_0 \|\hat{u}(x_0)\|^2 \leq E(x_0) \leq c_1 \|\hat{u}(x_0)\|^2.
\label{eq3.6-td}
\end{equation}

A straightforward calculation, together with~(\ref{eq3.6-td}), provides us with the following estimate:
\begin{eqnarray*}
\partial_{x_0}E(x_0) & = & \mathrm{Re}\left(\langle \partial_{x_0}a(x_0)\hat{u}(x_0), \hat{u}(x_0) \rangle + \langle a(x_0)\partial_{x_0}\hat{u}(x_0), \hat{u}(x_0)\right. \rangle\\
&&  \left. + \langle a(x_0)\hat{u}(x_0), \partial_{x_0}\hat{u}(x_0) \rangle \right)\\
& = & \mathrm{Re}\left(\langle \partial_{x_0}(x_0)\hat{u}(x_0), \hat{u}(x_0) \rangle \right)\\
&& +  \mathrm{Re}\left(i\xi\langle a(x_0)^2\hat{u}(x_0), \hat{u}(x_0) \rangle - \langle a(x_0)\hat{u}(x_0), a(x_0)\hat{u}(x_0) \rangle i\overline{\xi}\right).
\end{eqnarray*}
With $w=\langle a(x_0)^2\hat{u}(x_0), \hat{u}(x_0) \rangle$ and $z=i\xi$ the last two terms are of the form $zw-\overline{w}\;\overline{z}=zw-\overline{zw}$ so that the real part is zero. Therefore, we have

\begin{equation}
\partial_{x_0}E(x_0)=\mathrm{Re}\left(\langle \partial_{x_0}a(x_0)\hat{u}(x_0), \hat{u}(x_0) \rangle \right)\leq \sup_{x_0 \in [0,T]} |\partial_{x_0}a(x_0)| \|\hat{u}(x_0)\|^2.
\label{eq3.7-td}
\end{equation}
Putting $c' := c_0^{-1} \sup_{x_0 \in [0,T]} |\partial_{x_0}a(x_0)|$, we get from~(\ref{eq3.7-td}) using~(\ref{eq3.6-td}) that
\begin{equation}
\partial_{x_0}E(x_0)  \leq c'E(x_0).
\label{eq3.8-td}
\end{equation}
The last estimate allows us to apply Gronwall's lemma to~(\ref{eq3.8-td}), which leads to the existence of a constant $c > 0$ independent of $x_0 \in [0, T]$ such that
\begin{equation}
E(x_0) \leq cE(0).\label{eq3.9-td}
\end{equation}
Therefore, putting together~(\ref{eq3.9-td}) and~(\ref{eq3.6-td}), we obtain
\begin{equation*}
c_0\|\hat{u}(x_0)\|^2 \leq E(x_0) \leq cE(0) \leq cc_1\|\hat{u}(0)\|^2.
\end{equation*}
This means that there exists a constant $C > 0$ independent of $t$ such that $\|\hat{u}(x_0)\|^2 \leq C\|\hat{u}(0)\|^2$. From this we have
\begin{equation*}
\|u(x_0)\|^2  \leq C\|u_0\|^2,
\end{equation*}
as required.

\section{Notion of Very Weak Solution}

In this section, we revisit the concept of \textbf{very weak solutions}. Since this notion depends intrinsically on the structure of the differential equation under consideration, we adapt it to our specific framework involving distributions:
\begin{itemize}
    \item $a \in \mathcal{D}'([0, T])$ (for the coefficient),
    \item $f \in \mathcal{D}'([0, T]) \otimes \overline{H^{-\infty}(\mathbb{R})}$ (for the source term).
\end{itemize}

To define the solution rigorously, we employ a regularization procedure for both the distributional coefficient $a$ and the source term $f$. This is accomplished via convolution with a suitable mollifier $\psi$, which produces families of smooth functions $(a_\varepsilon)_\varepsilon$ and $(f_\varepsilon)_\varepsilon$ (regularized coefficients and regularized source terms), which
\begin{equation}
\label{eq1.7}
a_\varepsilon = a * \psi_{\omega(\varepsilon)} \quad \text{and} \quad f_\varepsilon = f(\cdot) * \psi_{\omega(\varepsilon)},
\end{equation}
with
\[
\psi_{\omega(\varepsilon)}(x_0) = (\omega(\varepsilon))^{-1} \psi(x_0 / \omega(\varepsilon)),
\]
where $\omega(\varepsilon) > 0$ satisfies  $\omega(\varepsilon) \to 0$ as $\varepsilon \to 0$, and $\psi$ is a Friedrichs-mollifier, which means that,
\[
\psi \in C_0^\infty(\mathbb{R}), \quad \psi \geq 0, \quad \int \psi = 1.
\]

Let us formally define nets of functions as follows.

\begin{definition}
\label{def-1.3-hip}
\begin{enumerate}
    \item[(i)] A net of functions $(f_\varepsilon)_\varepsilon \in C^\infty(\mathbb{R})^{(0,1]}$ is said to be $C^\infty$-moderate if for all $K \Subset \mathbb{R}$ and for all $\alpha \in \mathbb{N}_0$, there exist $N \in \mathbb{N}_0$ and $c > 0$ such that
    \[
    \sup_{t \in K} \| \partial^\alpha f_\varepsilon(x_0) \| \leq c \varepsilon^{-N-\alpha},
    \]
    for all $\varepsilon \in (0, 1]$, where $K \Subset \mathbb{R}$ means that $K$ is a compact set in $\mathbb{R}$.
    
    \item[(ii)] A net of functions $(u_\varepsilon)_\varepsilon \in C^\infty([0, T]; H^s)^{(0,1]}$ is $C^\infty([0, T]; H^s)$-moderate if there exist $N \in \mathbb{N}_0$ and $c_k > 0$ for all $k \in \mathbb{N}_0$ such that
    \[
    \| \partial_{x_0}^k u_\varepsilon(x_0, \cdot) \|_{H_R^s} \leq c_k \varepsilon^{-N-k},
    \]
    for all $x_0 \in [0, T]$ and $\varepsilon \in (0, 1]$.
    
    \item[(iii)] We say that a net of functions $(u_\varepsilon)_\varepsilon \in C^\infty([0, T]; H^{-\infty}(s))^{(0,1]}$ is $C^\infty([0, T]; H^{-\infty}(s))$-moderate if there exists $\eta > 0$, and for all $p \in \mathbb{N}_0$, there exist $c_p > 0$ and $N_p > 0$ such that
    \[
    \| e^{-\eta R^{\frac{1}{2s}}} \partial_{x_0}^p u_\varepsilon(x_0, \cdot) \|_{L^2(\Omega)} \leq c_p \varepsilon^{-N_p-p},
    \]
    for all $x_0 \in [0, T]$ and $\varepsilon \in (0, 1]$.
\end{enumerate}
\end{definition}
When $\omega(\varepsilon) = \varepsilon$, then the net $(a_\varepsilon)_\varepsilon$ from~(\ref{eq1.7}) satisfies $C^\infty$-moderateness. This is expected, since distribution regularizations are moderate  per se as the structure theorems of distribution theory which
\begin{equation}
\mathcal{E}'(\mathbb{R}) \subset \{ C^\infty\text{-moderate families} \}. \label{eq1.8}
\end{equation}

Thus, as seen in~(\ref{eq1.8}), we find that although the distributions in $\mathcal{E}'(\mathbb{R})$ do not provide solutions to our Cauchy problem, solutions might still be available in other settings.

The moderateness hypothesis provides the necessary framework for solution recovery via~(\ref{eq:1.6}) in solvable cases. We observe that classical Friedrichs mollification methods exhibit limitations in this context, thereby justifying the implementation of our $\omega(\varepsilon)$-based regularization approach.

Now let us introduce a notion of a ``very weak solution'' for the Cauchy problem:
\[
\begin{cases}
\partial_{x_0} u(x_0,\un{x}) + a(x_0) \mathcal{D} u(x_0,\un{x})= f(x_0,\un{x}), & (x_0,\un{x}) \in [0, T]\times \Omega, \\
u(0,\un{x}) = u_0{(\un{x})}, \qquad \un{x}\in \Omega.
\end{cases}
\]

\vspace*{0.1cm}
\begin{definition}
\label{def-1.4-hip}
Let $s$ be a real number.
\begin{enumerate}
    \item[(i)] We say that the net $(u_\varepsilon)_\varepsilon \subset C^\infty([0, T]; H_R^s)$ is a very weak solution of $H^s$-type of the Cauchy problem (1.9) if there exist $C^\infty$-moderate regularization $a_\varepsilon$ of the coefficient $a$, $C^\infty([0, T]; H_R^s)$-moderate regularization $f_\varepsilon$ of $f$, such that $(u_\varepsilon)_\varepsilon$ solves the following regularized problem:
    \[
    \begin{cases}
    \partial_t u_\varepsilon(x_0) + a_\varepsilon(x_0) \mathcal{D} u_\varepsilon(x_0) = f_\varepsilon(x_0), & t \in [0, T], \\
    u_\varepsilon(0) = u_0 \in L^2(\mathbb{R}^n).
    \end{cases} 
    \]
    for all $\varepsilon \in (0, 1]$, and is $C^\infty([0, T]; H_R^s)$-moderate.
    
    \item[(ii)] The net $(u_\varepsilon)_\varepsilon \subset C^\infty([0, T]; H^{-\infty}(s))$ is a very weak solution of $H^{-\infty}(s)$-type of the Cauchy problem (1.9) if there exist $C^\infty$-moderate regularization $a_\varepsilon$ of the coefficient $a$, $C^\infty([0, T]; H^{-\infty}(s))$-moderate regularization $f_\varepsilon(x_0)$ of $f(x_0)$, such that $(u_\varepsilon)_\varepsilon$ solves the regularized problem (1.10) for all $\varepsilon \in (0, 1]$, and is $C^\infty([0, T]; H^{-\infty}(s))$-moderate.
\end{enumerate}
\end{definition}

\section{Very weak solutions for Dirac operators with distributional coefficients}

\begin{theorem}{(\bf Theorem 1.5)}(Existence)
\label{th1.5}\\
Let $T > 0$ and $s \in \mathbb{R}$.
\begin{enumerate}
    \item[(i)] Let $a = a(x_0)$ be a positive distribution with compact support included in $[0, T]$, such that $a \geq a_0$ for some constant $a_0 > 0$. Let $u_0 \in H_R^s$ and $f \in D'([0, T]) \otimes \overline{H}_R^s$. Then the Cauchy problem (\ref{CP}) has a very weak solution of $H^s$-type.
    
    \item[(ii)] Let $a = a(x_0)$ be a nonnegative distribution with compact support included in $[0, T]$, such that $a \geq 0$. Let $u_0\in H^{-\infty}(s)$ and $f \in D'([0, T]) \otimes \overline{H^{-\infty}(s)}$. Then the Cauchy problem (\ref{CP}) has a very weak solution of $H^{-\infty}(s)$-type.
\end{enumerate}
\end{theorem}

Now we show that the very weak solution of the Cauchy problem~(\ref{CP}) is unique in an appropriate sense.

\begin{definition}{\bf Definition 1.6.}
\label{def1.6}
The net $(u_\varepsilon)_\varepsilon$ is $C^\infty$-negligible if for all $K \Subset \mathbb{R}$, for all $\alpha \in \mathbb{N}$ and for all $\ell \in \mathbb{N}$ there exists a positive constant $c$ such that
\[
\sup_{x_0 \in K} \| \partial^\alpha u_\varepsilon(x_0) \| \leq c \varepsilon^\ell,
\]
for all $\varepsilon \in (0, 1]$.\\
\end{definition}
In the present framework, it suffices to consider $K = [0, T]$, as all temporal distributions of interest are supported in $[0, T]$.

\subsection*{Proof of Theorem 1.5}

\noindent
\begin{proof}[Proof of Theorem 1.5.]
(i) Suppose the coefficient $a = a(x_0)$ is a distribution with compact support in $[0, T]$. In this case, the classical formulation of problem~(\ref{CP}) may fail in the distributional framework due to the well-known difficulties in defining products of distributions. To address this challenge, we instead consider a regularized version of~\eqref{CP}. Specifically, through mollification of $a$ using $\psi \in C_{0}^{\infty}(\mathbb{R})$, we generate a family of smooth coefficients $(a_{\varepsilon})_{\varepsilon}$, which enables a rigorous analysis.

For this, we take $\psi\in C_{0}^{\infty}(\mathbb{R})$, $\psi\geq 0$ with $\int\psi=1$, and $\omega(\varepsilon)>0$ such that $\omega(\varepsilon)\to 0$ as $\varepsilon\to 0$ to be chosen later. Then, we define $\psi_{\omega_{\varepsilon}}$ and $a_{\varepsilon}$ by

\[
\psi_{\omega_{\varepsilon}}(x_0):=\frac{1}{\omega(\varepsilon)}\psi\left(\frac{x_0}{\omega(\varepsilon)}\right)
\]

and

\[
a_{\varepsilon}(x_0):=(a*\psi_{\omega(\varepsilon)})(x_0)
\]

for all $x_0\in[0,T]$, respectively. Using these representations of $\psi_{\omega_{\varepsilon}}$ and $a_{\varepsilon}$ and identifying the measure $a(x_0)$ with its density, we get

\[
a_{\varepsilon}(x_0)=(a*\psi_{\omega(\varepsilon)})(x_0)=\int\limits_{\mathbb{R}}a(x_0-\tau)\psi_{\omega(\varepsilon)}(\tau)d\tau=\int\limits_{\mathbb{R}}a(x_0-\omega(\varepsilon)\tau)\psi(\tau)d\tau
\]

\[
=\int\limits_{K}a(x_0-\omega(\varepsilon)\tau)\psi(\tau)d\tau\geq a_{0}\int\limits_{K}\psi(\tau)d\tau:=\widetilde{a_{0}}>0,
\]

where we have used that $a(x_0)$ is a positive distribution with compact support (hence a Radon measure) and $\psi\in C_{0}^{\infty}(\mathbb{R})$, supp $\psi\subset K$, $\psi\geq 0$ in above. Here, note that $\widetilde{a_{0}}$ does not depend on $\varepsilon$.

We also note that by virtue of the structure theorem for compactly supported distributions, there exist a natural number $L$ and positive constant $c$ such that for all $k\in\mathbb{N}_{0}$ and $x_0\in[0,T]$ we have

\begin{equation}
   |\partial_{x_0}^{k}a_{\varepsilon}(x_0)|\leq c(\omega(\varepsilon))^{-L-k}.
\label{eq3.3-hipoel} 
\end{equation}


Thus, $a_{\varepsilon}$ is $C^{\infty}$-moderate regularisation of the coefficient $a(x_0)$ under appropriate conditions on $\omega(\varepsilon)$, then fixing $\varepsilon\in(0,1]$ we consider the following regularised problem

\begin{equation}
\left\{
\begin{array}{l}
\partial_{x_0}u_{\varepsilon}(x_0)+a_{\varepsilon}(x_0)\mathcal{D}u_{\varepsilon}(x_0)=0,\ x_0\in[0,T], \\
u_{\varepsilon}(0)=u_{0}\in L^{2}(\mathbb{R}^n), 
\end{array}
\right. 
\label{eq3.4-hipoel} 
\end{equation}

where $u_{0}\in H^s$, $a_{\varepsilon}\in C^{\infty}[0,T]$. Then, Theorem~\ref{th1.1} implies that the regularised problem~(\ref{eq3.4-hipoel}) has a unique solution in the space $C([0,T]; H^s)$. Actually, noting \(a_{\varepsilon}\in C^{\infty}([0,T])\) and differentiating both sides of the equation~(\ref{eq3.4-hipoel}) in \(x_0\) inductively, one can see that this unique solution is from \(C^{\infty}([0,T];H{\varepsilon})\).\\

Thus, recalling $S(x_0):= a(x_0)$ 
by the proof of Theorem~\ref{th1.1} or Theorem~\ref{th1.2} with \(f\equiv 0\)), and noting~(\ref{eq3.3-hipoel}), we get

\[
\|\partial_{x_0}S(x_0)\|\leq C|\partial_{x_0}a_{\varepsilon}(x_0)|\leq C\omega(\varepsilon)^{-L-1}.
\]

Then, from~\ref{eq3.4-hipoel}  \(f\equiv 0\)), Gronwall's lemma with \(f\equiv 0\)) imply that

\begin{equation}
\|u_{\varepsilon}(x_0,\cdot)\|^{2}_{ H^s(\mathbb{R}^n)} \leq C\exp(c\omega(\varepsilon)^{-L-1}T)\|u_{0}\|^{2}_{ H^s(\mathbb{R}^n)}. ~\label{eq3.5-hipoel}
\end{equation}

If we take \((\omega(\varepsilon))^{-L-1}\approx\log\varepsilon\), then~(\ref{eq3.5-hipoel}) becomes

\[
\|u_{\varepsilon}(x_0,\cdot)\|^{2}_{ H^s(\mathbb{R}^n)} \leq C\varepsilon^{-L-1}\|u_{0}\|^{2}_{ H^s(\mathbb{R}^n)},
\]

with possibly new constant \(L\).

Now, to obtain that \(u_{\varepsilon}\) is \(C^{\infty}([0,T];H^{\varepsilon})\)-moderate, we need to show that for all \(x_0\in[0,T]\) and \(\varepsilon\in(0,1]\),

\begin{equation}
\|u_{\varepsilon}(x_0,\cdot)\|_{ H^s(\mathbb{R}^n)}\leq C\varepsilon^{-L}
\label{eq3.6-hipoel}
\end{equation}

hold for some \(L>0\). Indeed, once we prove this, then acting by the iterations of \(\partial_{t}\) on the equality

\[
\partial_{x_0}u_{\varepsilon}(x_0)=-a_{\varepsilon}(x_0){\mathcal{D}}u_{\varepsilon}(x_0),
\]

and taking it in \(L^{2}({\mathbb{R}^n})\)-norms, we conclude that \(u_{\varepsilon}\) is \(C^{\infty}([0,T];H^{\varepsilon})\)-moderate. 

Since \(u_{\varepsilon}\) is \(C^{\infty}([0,T];H^{s})\)-moderate, by the Definition~\ref{def-1.4-hip} we conclude that the Cauchy problem (\ref{CP}) has a very weak solution.\\

Now we prove Part (ii). Similarly as in Part (i), in this case one gets that for \(a_{\varepsilon}(x_0)\geq 0\) there are \(L\in\mathbb{N}\) and \(c_{1}>0\) such that

\begin{equation}
|\partial_{x_0}^{k}a_{\varepsilon}(x_0)|\leq c_{1}(\omega(\varepsilon))^{-L-k}, 
\label{eq3.7-hipoel}
\end{equation}

for all \(k\in\mathbb{N}_{0}\) and \(x_0\in[0,T]\), which means that \(a_{\varepsilon}(x_0)\) is a \(C^{\infty}\)-moderate regularisation of \(a(x_0)\). Then, fixing \(\varepsilon\in(0,1]\), we consider the following regularised problem

\begin{equation}
\left\{
\begin{array}{l}
\partial_{x_0}u_{\varepsilon}(x_0)+a_{\varepsilon}(x_0){\mathcal{D}}u_{\varepsilon}(x_0)=0,\ x_0\in[0,T], \\
u_{\varepsilon}(0)=u_{0}\in L^{2}(\mathbb{R}^n),
\end{array}
\right. 
\label{eq3.8-hipoel}
\end{equation}

where \(u_{0}\in H_{{(s)}}^{-\infty}\) and \(a_{\varepsilon}\in C^{\infty}[0,T]\). Then, we can usethe Theorem~\ref{th1.2}, which implies that the equation~(\ref{eq3.8-hipoel}) has a unique solution in the space \(u\in C^{1}([0,T];H_{{(s)}}^{-\infty})\) for any \(s\). Actually, this unique solution is from \(C^{\infty}([0,T];H_{{(s)}}^{-\infty})\), which can be checked by differentiating both sides of the equation~(\ref{eq3.8-hipoel}) in \(x_0\) inductively noting that \(a_{\varepsilon}\in C^{\infty}([0,T])\). Applying Theorem~\ref{th1.2} (iii) to the equation~(\ref{eq3.8-hipoel}), using the inequality

\[
|\partial_{x_0}a_{\varepsilon}(x_0)|\leq C(\omega(\varepsilon))^{-L-1}.
\]
This completes the proof of Theorem~\ref{th1.5}. 
\end{proof}
Now we prove Theorem~\ref{th1.7}.

\newpage


%%%%%%%%

\begin{theorem}{(\bf Theorem 1.7)}
\label{th1.7}(Uniqueness)\\
Let $T > 0$.
\begin{enumerate}
    \item[(i)] Let $a = a(x_0)$ be a positive distribution with compact support included in $[0, T]$, such that $a(x_0) \geq a_0$ for some constant $a_0 > 0$. Let $u_0 \in H^s$ and $f \in L^2([0, T]; H^s)$ for some $s \in \mathbb{R}$. Then there exists an embedding of the coefficient $a(x_0)$ into $G([0, T])$, such that the Cauchy problem~(\ref{CP}) has a unique solution $u \in L^2([0, T]; H^s)$.
    
    \item[(ii)] Let $a = a(x_0) \geq 0$ be a nonnegative distribution with compact support included in $[0, T]$. Let $u_0\in H^{-\infty}(s)$ and $f \in L^2([0, T]; H^{-\infty}(s))$ for some $s \in \mathbb{R}$. Then there exists an embedding of the coefficient $a(x_0)$ into $L^2([0,T])$, such that the Cauchy problem~(\ref{CP}) has a unique solution $u \in L^2([0,T]; H_{(s)}^{-\infty})$.
\end{enumerate}
\end{theorem}
Now we give the consistency result, which means that very weak solutions recapture the classical solutions in the case the latter exist. 

Denote by $L_{1}^{\infty}([0,T])$ the space of bounded functions on $[0,T]$ with the derivative also in $L^{\infty}$.

\vspace{0.5cm}


\textbf{Proof of Theorem~\ref{th1.7}}\\
(i) We assume that the Cauchy problem has another solution $v \in L^2([0, T]; H^s)$. At the level of representatives this means

\[
\begin{cases}
\partial_{x_0} (u_\varepsilon - v_\varepsilon)(x_0) + a_\varepsilon(x_0)\mathcal{D}(u_\varepsilon - v_\varepsilon)(x_0) = \rho_\varepsilon(x_0), & x_0 \in [0, T], \\
(u_\varepsilon - v_\varepsilon)(0) = 0,
\end{cases}
\]

with  $\rho_\varepsilon = ( a_\varepsilon(x_0)-\widetilde{a}_\varepsilon(x_0) )\mathcal{D}v_\varepsilon(x_0)$, where $(\widetilde{a}_\varepsilon)_\varepsilon$ is an approximation corresponding to $u_\varepsilon$. Since $(a_\varepsilon)_\varepsilon \sim (\widetilde{a}_\varepsilon)_\varepsilon$, we have that $\rho_\varepsilon$ is $C^\infty([0, T]; H^s)$-negligible. Let us write this as in the following first order equation
\[
\partial_{x_0} W_{\varepsilon} +  a_\varepsilon(x_0)\mathcal{D}  W_{\varepsilon} =\rho_\varepsilon,
\]
where
\[
W_{\varepsilon} := (u_\varepsilon - v_\varepsilon).
\]


Using the Fourier transform,
\[
\partial_{x_0} V_\varepsilon(x_0, \xi) + i \xi A_\varepsilon(x_0, \xi) V_\varepsilon(x_0, \xi) = P_\varepsilon(x_0, \xi),
\]

for all $\xi \in \mathbb{R}^n$. We define the energy
\[
E_\varepsilon(x_0, \xi) := \mathrm{Re}(S_\varepsilon(x_0, \xi) V_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi))
\]
for the symmetriser $S_\varepsilon(x_0, \xi) =  a_\varepsilon(x_0)$. Since $a_\varepsilon(x_0)$ is continuous, then from the definition of the energy we get
\begin{equation}
\label{eq3.12}
c_0 |V_\varepsilon(x_0, \xi)|^2 \leq E_\varepsilon(x_0, \xi) \leq c_1 |V_\varepsilon(x_0, \xi)|^2
\end{equation}
for some positive constants $c_0$ and $c_1$. Then, a direct calculation gives that
\begin{gather*}
\partial_{x_0} E_\varepsilon(x_0, \xi) = \mathrm{Re}\big[(\partial_{x_0} S_\varepsilon(x_0, \xi)V_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi)) + (S_\varepsilon(x_0, \xi) \partial_{x_0} V_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi))\\ + (S_\varepsilon(x_0, \xi) V_\varepsilon(x_0, \xi), \partial_{x_0} V_\varepsilon(x_0, \xi))\big]\\
= \mathrm{Re}\big[(\partial_{x_0} S_\varepsilon(x_0, \xi) V_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi)) + i \xi (S_\varepsilon(x_0, \xi)A_\varepsilon(t, \xi)V_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi))\\
- i \xi (S_\varepsilon(x_0, \xi)V_\varepsilon(x_0, \xi), A_\varepsilon(x_0, \xi) V_\varepsilon(x_0, \xi)) + (S_\varepsilon(x_0, \xi)P_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi)) +\\ (S_\varepsilon(x_0, \xi)V_\varepsilon(x_0, \xi), P_\varepsilon(x_0, \xi))\big]\\
= \mathrm{Re}\big[(\partial_{x_0} S_\varepsilon(x_0, \xi)V_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi)) + i \xi ((S_\varepsilon A_\varepsilon - A^*_\varepsilon S_\varepsilon)(x_0, \xi) V_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi)) \\+ (S_\varepsilon(x_0, \xi)P_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi)) + (V_\varepsilon(x_0, \xi), S_\varepsilon(x_0, \xi) P_\varepsilon(x_0, \xi))\big]\\ = \mathrm{Re}\big[(\partial_{x_0} S_\varepsilon(x_0, \xi)V_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi)) + 2 \text{Re}(S_\varepsilon(x_0, \xi) P_\varepsilon(x_0, \xi), V_\varepsilon(x_0, \xi))\big]
\end{gather*}
\begin{equation}
\label{eq.3.13}
 \leq |\partial_{x_0} S_\varepsilon| |V_\varepsilon(x_0, \xi)|^2 + 2 |S_\varepsilon| |P_\varepsilon(x_0, \xi)| |V_\varepsilon(x_0, \xi)|,   
\end{equation}


where we have used $(S_\varepsilon A_\varepsilon - A^*_\varepsilon S_\varepsilon)(x_0, \xi) = 0$. \\
In the case where $|V_\varepsilon(x_0, \xi)| \geq 1$, taking into account~(\ref{eq3.12}) we obtain from the above that
\begin{gather*}
\partial_{x_0} E_\varepsilon(x_0, \xi)\leq \|\partial_{x_0} S_\varepsilon\| |V_\varepsilon(x_0, \xi)|^2 + 2 \|S_\varepsilon\| |P_\varepsilon(x_0, \xi)| |V_\varepsilon(x_0, \xi)|\\
 \leq (\|\partial_{x_0} S_\varepsilon\| + 2 \|S_\varepsilon\| |P_\varepsilon(x_0, \xi)|) |V_\varepsilon(x_0, \xi)|^2 \\
\leq (|\partial_{x_0} a_\varepsilon(x_0)| + 2 |a_\varepsilon(x_0)| |P_\varepsilon(x_0, \xi)|) |V_\varepsilon(x_0, \xi)|^2 \leq c (\omega(\varepsilon))^{-L-1} E_\varepsilon(x_0, \xi)
\end{gather*}
for some constant $c > 0$. Then, the Gronwall lemma implies that
\[
E_\varepsilon(x_0, \xi) \leq \exp(c (\omega(\varepsilon))^{-L-1} T) E_\varepsilon(0, \xi)
\]
for all $T > 0$. Hence, by~(\ref{eq3.12}) we obtain for the constant $c_1$ independent of $t \in [0, T]$ and $\xi$ that
\[
c_0 |V_\varepsilon(x_0, \xi)|^2 \leq E_\varepsilon(x_0, \xi)\leq \exp(c (\omega(\varepsilon))^{-L-1} T) E_\varepsilon(0, \xi) \leq \exp(c_1 (\omega(\varepsilon))^{-L-1} T) |V_\varepsilon(0, \xi)|^2.
\]
Choosing $(\omega(\varepsilon))^{-L-1} \approx \log \varepsilon$, we get
\[
|V_\varepsilon(x_0, \xi)|^2 \leq c \varepsilon^{-L-1} |V_\varepsilon(0, \xi)|^2
\]
for some positive constant $c$ and some $L$. It implies for all $\xi$ and $x_0 \in [0, T]$ that
\[
|V_\varepsilon(x_0, \xi)| \equiv 0,
\]
since $|V_\varepsilon(0, \xi)| = 0$.

Now let us consider the case $|V_\varepsilon(x_0, \xi)| < 1$. Assume that
\[
|V_\varepsilon(x_0, \xi)| \geq c (\omega(\varepsilon))^\alpha
\]
for some constant $c$ and $\alpha > 0$, i.e.
\begin{equation}
\label{eq3.15}
\frac{1}{|V_\varepsilon(x_0, \xi)|} \leq C (\omega(\varepsilon))^{-\alpha}.
\end{equation}
In this case, from~(\ref{eq3.15}) noting



\[
|V_\varepsilon(x_0, \xi)| = \frac{|V_\varepsilon(x_0, \xi)|^2}{|V_\varepsilon(x_0, \xi)|} \leq C (\omega(\varepsilon))^{-\alpha} |V_\varepsilon(x_0, \xi)|^2
\]
and~(\ref{eq3.12}), we get from~(\ref{eq.3.13}) the following energy estimate
\[
\partial_t E_\varepsilon(x_0, \xi) \leq C (\omega(\varepsilon))^{-L_1} E_\varepsilon(x_0, \xi),
\]
where $L_1 = L + \max\{\alpha\}$. Again applying the Gronwall lemma, we arrive at
\[
|V_\varepsilon(x_0, \xi)|^2 \leq \exp(C' (\omega(\varepsilon))^{-L_1} T) |V_\varepsilon(0, \xi)|^2.
\]
Then, taking $(\omega(\varepsilon))^{-L_1} \approx \log \varepsilon$, it follows that
\[
|V_\varepsilon(x_0, \xi)|^2 \leq c' \varepsilon^{-L_1} |V_\varepsilon(0, \xi)|^2
\]
for some $c'$ and some (new) $L_1$, which implies
\[
|V_\varepsilon(x_0, \xi)| = 0
\]
for all $\xi$ and $x_0 \in [0, T]$, since we have $|V_\varepsilon(0, \xi)| = 0$.

The case $|V_\varepsilon(x_0, \xi)| \leq c (\omega(\varepsilon))^\alpha$ for some constant $c$ and $\alpha > 0$ is trivial. Thus, the first part is proved.


\vspace{0.5cm}
(ii) We prove this part in the similar way as Part (i) but using the quasi-symmetrisers. We assume that the Cauchy problem has another solution $u \in \mathcal{G}([0, T]; H^{-\infty}_{(s)})$. At the level of representatives this means that
\[
\begin{cases}
\partial_{x_0} (u_\varepsilon - v_\varepsilon)(x_0) + a_\varepsilon(x_0)\mathcal{D}(u_\varepsilon - v_\varepsilon)(x_0) = \rho_\varepsilon(x_0), & x_0 \in [0, T], \\
(u_\varepsilon - v_\varepsilon)(0) = 0,
\end{cases}
\]
where $\rho_\varepsilon$ is $C^\infty([0, T]; H^{-\infty}_{(s)})$-negligible. 
The equation will be studied after the group Fourier transform, as a system of the type
\[
\partial{x_0} V_\varepsilon(x_0, \xi) + i \xi A_\varepsilon(x_0, \xi) V_\varepsilon(x_0, \xi)= P_\varepsilon(x_0, \xi),
\]
for all $\xi \in \mathbb{R}^n$ where $P_\varepsilon(x_0, \xi) = \mathcal{F}\rho_\varepsilon$.


Taking into account the properties in the proof of the Theorem~\ref{th1.1} we conclude that the Cauchy problem~(\ref{CP}) has a unique solution $v \in L^2([0, T]; H^{-\infty}_{(s)})$ for all $s \in \mathbb{R}$.\\
This completes the proof of Theorem~\ref{th1.7}. 

\begin{theorem}(Consistency-1)
\label{th1.8}
Let $T > 0$.
\begin{enumerate}
    \item[(i)] Let $a \in L^\infty_1([0, T])$ with $a(x_0) \geq a_0 > 0$. Let $s \in \mathbb{R}$, $u_0 \in H^{s}$ and $f \in C([0, T]; H^s)$. Let $u$ be a very weak solution of $H^s$-type of~(\ref{CP}). Then for any regularising families $a_\varepsilon$ and $f_\varepsilon$ in Definition~\ref{def-1.4-hip}, any representative $(u_\varepsilon)_\varepsilon$ of $u$ converges in $C([0, T]; H^{s})$ as $\varepsilon \to 0$ to the unique classical solution in $C([0, T]; H^{s})$ of the Cauchy problem~(\ref{CP}) given by Theorem~\ref{th1.2}.
    
    \item[(ii)] Let $a \in C^\ell([0, T])$ with $\ell \geq 2$ be such that $a(x_0) \geq 0$. Let $1 \leq s < 1 + \ell/2$ and $u_0\in H^{-\infty}(s)$ and $f \in C([0, T]; H^{-\infty}(s))$. Let $u$ be a very weak solution of $H^{-\infty}(s)$-type of~(\ref{CP}). Then for any regularizing families $a_\varepsilon$ and $f_\varepsilon$ in Definition~\ref{def-1.4-hip}, any representative $(u_\varepsilon)_\varepsilon$ of $u$ converges in $C^2([0, T]; H^{-\infty}(s))$ as $\varepsilon \to 0$ to the unique classical solution in $C^2([0, T]; H^{-\infty}(s))$ of Cauchy problem~(\ref{CP}) given by Theorem~\ref{th1.2}.
\end{enumerate}
\end{theorem}

Similarly, we can show other consistency ``cases'' of Theorem~\ref{th1.8} as following.

\begin{theorem}(Consistency-2)
\label{th1.9}
Let $T > 0$.
\begin{enumerate}
    \item[(i)] Let $a(x_0) \geq a_0 > 0$ and $a \in C^\alpha([0, T])$ with $0 < \alpha < 1$. Let $1 \leq s < 1 + \alpha/(1 - \alpha)$, $u_0 \in H^{-\infty}(s)$ and $f \in C([0, T]; H^{-\infty}(s))$. Let $u$ be a very weak solution of $H^{-\infty}(s)$-type of~(\ref{CP}). Then for any regularising families $a_\varepsilon$ and $f_\varepsilon$ in Definition~\ref{def-1.4-hip}, any representative $(u_\varepsilon)_\varepsilon$ of $u$ converges in $C^2([0, T]; H^{-\infty}(s))$ as $\varepsilon \to 0$ to the unique classical solution in $C^2([0, T]; H^{-\infty}(s))$ of the Cauchy problem~(\ref{CP}) given by Theorem~\ref{th1.2}.
    
    \item[(ii)] Let $a(x_0) \geq 0$ and $a \in C^\alpha([0, T])$ with $0 < \alpha < 2$. Let $1 \leq s < 1 + \alpha/2$, $u_0 \in H^{-\infty}(s)$ and $f \in C([0, T]; H^{-\infty}(s))$. Let $u$ be a very weak solution of $H^{-\infty}(s)$-type of~(\ref{CP}). Then for any regularising families $a_\varepsilon$ and $f_\varepsilon$ in Definition~\ref{def-1.4-hip}, any representative $(u_\varepsilon)_\varepsilon$ of $u$ converges in $C^2([0, T]; H^{-\infty}(s))$ as $\varepsilon \to 0$ to the unique classical solution in $C^2([0, T]; H^{-\infty}(s))$ of the Cauchy problem~(\ref{CP}) given by Theorem~\ref{th1.2}.
\end{enumerate}
\end{theorem}


\section*{Proof of Theorem~\ref{th1.8}}

\subsection*{Comparison of Classical Solution and Very Weak Solution}

Here, we compare the classical solution $\tilde{u}$ given by Theorem~\ref{th1.1} with the very weak solution $u$ provided by Theorem~\ref{th1.8}. By the definition of the classical solution, we have for the classical solution $\tilde{u}$:
\begin{equation}
\begin{cases}
\partial_{x_0} \tilde{u}(x_0) + a(x_0) D \tilde{u}(x_0) = 0, & x_0 \in [0, T], \\
\tilde{u}(0) = u_0 \in L^2(\mathbb{R}^n).
\end{cases}
\label{eq3.18}
\end{equation}

From the definition of the very weak solution $u$, we also know that there exists a representative $(u_\varepsilon)_\varepsilon$ of $u$ such that:
\begin{equation}
\begin{cases}
\partial_{x_0} u_\varepsilon(x_0) + a_\varepsilon(x_0) D u_\varepsilon(x_0) = 0, & x_0 \in [0, T], \\
u_\varepsilon(0) = u_0 \in L^2(\mathbb{R}^n),
\end{cases}
\label{eq3.19}
\end{equation}
for suitable embeddings of $a(x_0)$. Since $(a_\varepsilon - a)_\varepsilon \to 0$ in $C([0, T])$ for $a \in L^\infty_1([0, T])$, then \eqref{eq3.18} becomes:
\begin{equation}
\begin{cases}
\partial_{x_0} \tilde{u}(x_0) + a_\varepsilon(x_0) D \tilde{u}(x_0) = n_\varepsilon(x_0), & x_0 \in [0, T], \\
\tilde{u}(0) = u_0 \in L^2(G),
\end{cases}
\label{eq3.20}
\end{equation}
where $n_\varepsilon(x_0) = (a_\varepsilon(x_0) - a(x_0)) D \tilde{u}(x_0) \in C([0, T]; H^s)$ and converges to $0$ in this space as $\varepsilon \to 0$.

By virtue of \eqref{eq3.19} and \eqref{eq3.20}, we note that $\tilde{u} - u_\varepsilon$ solves the following Cauchy problem:
\begin{equation}
\begin{cases}
\partial_{x_0} (\tilde{u} - u_\varepsilon)(x_0) + a_\varepsilon(x_0) D (\tilde{u} - u_\varepsilon)(x_0) = n_\varepsilon(x_0), & x_0 \in [0, T], \\
(\tilde{u} - u_\varepsilon)(0) = 0, \\
(\partial_{x_0} \tilde{u} - \partial_{x_0} u_\varepsilon)(0) = 0.
\end{cases}
\label{eq:3.21}
\end{equation}

Then, similarly as in the proof of Theorem~\ref{th1.7}, we apply Fourier transform to get the following energy estimate:
\[
\partial_{x_0} E_\varepsilon(x_0, \xi) \leq \|\partial_{x_0} a_\varepsilon(x_0)\| \|(\tilde{V} - V_\varepsilon)(x_0, \xi)\|^2 + 2 \|a_\varepsilon(x_0)\| \|n_\varepsilon(x_0, \xi)\| \|(\tilde{V} - V_\varepsilon)(x_0, \xi)\|,
\]
which implies:
\[
\partial_{x_0} E_\varepsilon(x_0, \xi) \leq c_1 \|(\tilde{V} - V_\varepsilon)(x_0, \xi)\|^2 + c_2 \|n_\varepsilon(x_0, \xi)\| \|(\tilde{V} - V_\varepsilon)(x_0, \xi)\|,
\]
since the coefficient $a_\varepsilon(x_0)$ is regular enough. Then, noting $\|(\tilde{V} - V_\varepsilon)(0, \xi)\| = 0$ and $n_\varepsilon \to 0$ in $C([0, T]; H^s)$, and continuing to discuss as in Theorem~\ref{th1.7}, we arrive at:
\[
\|(\tilde{V} - V_\varepsilon)(x_0, \xi)\| \leq c (\omega(\varepsilon))^\alpha,
\]
for some positive constants $c$ and $\alpha$, which concludes that:
\[
u_\varepsilon \to \tilde{u} \quad \text{in } C([0, T]; H^s) .
\]
Furthermore, since any other representative of $u$ will differ from $(u_\varepsilon)_\varepsilon$ by a $C^\infty([0, T]; H^s)$-negligible net, the limit is the same for any representative of $u$.

\subsection*{(ii) Proof of Part (ii)}

Part (ii) can be proven as Part (i) with slight modifications.

This completes the proof of Theorem~\ref{th1.8}. $\Box$



%%%% KIRA FROM HERE%%%%%%%%
 \hrulefill

 Adapting the results from the paper, firstly the case where the right hand side of the equation is null.
 \[
\begin{cases}
    v_t(x_0) - i\beta a(x_0) v(x_0) = 0\\
    v(0) = v_0
\end{cases}
\]


Case 1: $a \in Lip([0,T])$, $a(x_0) \geq a_0 > 0$. This is the simplest case that can be
treated by a classical argument. 

Thus we define the energy as
\[E(x_0) :=(a(x_0)v(x_0), v(x_0))\]

In this case the continuity of $a(x_0)$ ensures the existence of two strictly
positive constants $a_0$ and $a_1$ such that:
\[a_0 = \min_{t\in[0,T]}a(x_0) \qquad and \qquad a_1 = \max_{t\in[0,T]}a(x_0).\]

A straightforward calculation to estimate its variations in time yields
the following inequality that will help us to get such estimate:
\[a_0\norm{v(x_0)}^2 \leq E(x_0) \leq a_1\norm{v(x_0)}^2 .\]
A straightforward calculation, together with (3.6), gives the following estimate:

\begin{align*}
    E_t(x_0)  &=(a_t(x_0)v (x_0), v (x_0)) + (a(x_0)v_t (x_0), v (x_0)) + (a(x_0)v (x_0), v_t (x_0))\\
            &=(a_t(x_0)v (x_0), v (x_0)) + i\beta(a(x_0)a(x_0)v(x_0), v (x_0)) - i\beta(a(x_0)v (x_0), a(x_0)v (x_0))\\
            &=(a_t(x_0)v (x_0), v (x_0))\\
            &=\norm{a_t(x_0)}\norm{v(x_0)}^2
\end{align*}

thus setting 
\[c' := a_0^{-1}\sup_{t\in[0,T]}\norm{a_t(x_0)}\]
we get from (3.7) using (3.6) that
\[E_t(x_0) \leq c'E(x_0).\]
Applying the Gronwall lemma to (3.8), we deduce that there exists a constant $c > 0$ independent of $t \in [0, T]$ such that:
\[E(x_0) \leq cE(0).\]
Therefore, putting together (3.9) and (3.6) we obtain
\[a_0\norm{v (x_0)}^2 \leq E(x_0) \leq cE(0) \leq ca_1\norm{v (0)}^2 = ca_1\norm{v_0}^2\]

We can then rephrase this, asserting that there exists a constant $C > 0$ independent
of t such that 
\[\norm{v (x_0)}^2 \leq C\norm{v_0}^2.\]

Now fourrier transform
\[
\begin{cases}
\hat{u}_t(t, \x) -i\xi a(x_0)\hat{u}(x_0, \x) = 0\\
\hat{u}(0, \x) = \hat{u}_0(\x)
\end{cases}
\]

this is the same as above so we get:
\[\norm{\hat{u}(x_0, \x)}^2 \leq C\norm{\hat{u}_0(\x)}^2\]

\hrulefill

Now for the case $f\neq0$
 \[
\begin{cases}
    v_t(x_0) - i\beta a(x_0) v(x_0) = f(x_0)\\
    v(0) = v_0
\end{cases}
\]


Case 1: $a \in Lip([0,T])$, $a(x_0) \geq a_0 > 0$. This is the simplest case that can be
treated by a classical argument. 

Thus we define the energy as
\[E(x_0) :=(a(x_0)v(x_0), v(x_0))\]

In this case the continuity of $a(x_0)$ ensures the existence of two strictly
positive constants $a_0$ and $a_1$ such that:
\[a_0 = \min_{t\in[0,T]}a(x_0) \qquad and \qquad a_1 = \max_{t\in[0,T]}a(x_0).\]

A straightforward calculation to estimate its variations in time yields
the following inequality that will help us to get such estimate:
\[a_0\norm{v(x_0)}^2 \leq E(x_0) \leq a_1\norm{v(x_0)}^2 .\]
A straightforward calculation, together with (3.6), gives the following estimate:
\begin{align*}
    E_t(x_0)  &=(a_t(x_0)v (x_0), v (x_0)) + (a(x_0)v_t (x_0), v (x_0)) + (a(x_0)v (x_0), v_t (x_0))\\
            &=(a_t(x_0)v (x_0), v (x_0)) + [a(x_0)(i\beta a(x_0)v(x_0) + f(x_0)), v (x_0)] + [a(x_0)v (x_0), (i\beta a(x_0)v(x_0) + f(x_0))]\\
            &=(a_t(x_0)v (x_0), v (x_0)) + (a(x_0)f (x_0), v(x_0)) + (a(x_0)v(x_0), f(x_0))\\
            &=\norm{a_t(x_0)}(v (x_0), v (x_0)) +2a(x_0)Re(f(x_0), v(x_0))\\
            &\leq(\norm{a_t(x_0)} + 1)\norm{v(x_0)}^2+a^2(x_0)\norm{f(x_0)}^2\\
            &\leq \sup_{t \in [0,T]}\{\norm{a_t(x_0)} + 1\} \norm{v(x_0)} +a^2(x_0)\norm{f(x_0)}^2\\
            &\leq C_1E(x_0) + C_2\norm{f(x_0)}^2
\end{align*}

for some positive constants C1 and C2. Applying Gronwall’s lemma and noting (4.7),
we get

\[\norm{v (x_0)}^2 \leq a_0^{-1}E(x_0) \leq C_1\norm{v (0)}^2 +  C_2\sup_{t \in [0,T]}\norm{f(x_0)}^2\]

Now fourrier transform
\[
\begin{cases}
\hat{u}_t(t, \x) -i\xi a(x_0)\hat{u}(x_0, \x) = \hat{f}\\
\hat{u}(0, \x) = \hat{u}_0(\x)
\end{cases}
\]

this is the same as above so we get:
\[\norm{\hat{u}(x_0, \x)}^2 \leq C_1\norm{\hat{u}_0(\x)}^2 + C_2\norm{\hat{f}(\x)}^2\]

\hrulefill
%%%%


\begin{thebibliography}{2025}

\bibitem{BDS} F. Brackx, R. Delanghe, and F. Sommen, Clifford Analysis, Pitman-Longman, 1982.

\bibitem{DSS}
R. Delanghe, F. Sommen and V. Sou\u{c}ek, \textit{Clifford algebras and spinor-valued functions. A function theory for the Dirac operator}, Mathematics and its Applications-Vol.53, Kluwer Academic Publishers,
Dordrecht etc., 1992.


\bibitem{HSOE-GarettoRuz}
Garetto, C., Ruzhansky, M. Hyperbolic Second Order Equations with Non-Regular Time Dependent Coefficients. Arch Rational Mech Anal 217, 113–154 (2015). https://doi.org/10.1007/s00205-014-0830-1

\bibitem{GS} K. G\"urlebeck; W. Spr\"ossig. \textit{Quaternionic and Clifford Calculus for Physicists and Engineers}, Wiley and Sons Publ., 1997.	


\bibitem{VWS-YessinkegenovRuz}
Ruzhansky, M.,  Yessirkegenov, N.  Very weak solutions to hypoelliptic wave equations. J. Differential Equations, 268 (2020), no. 5, 2063–2088.
\end{thebibliography}


\end{document}